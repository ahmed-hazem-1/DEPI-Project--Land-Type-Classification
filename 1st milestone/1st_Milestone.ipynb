{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f35bd610",
      "metadata": {
        "id": "f35bd610"
      },
      "source": [
        "# üéØ Milestone 1: Data Collection, Exploration, and Preprocessing  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 1: Setup & Mount Google Drive\n"
      ],
      "metadata": {
        "id": "vZQU5LxSQ3K8"
      },
      "id": "vZQU5LxSQ3K8"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚úÖ Step 2: Import Required Libraries\n",
        "import os\n",
        "import cv2\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "CRzJE6WmQ6Dz"
      },
      "id": "CRzJE6WmQ6Dz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 2: Define Paths & Dataset Parameters"
      ],
      "metadata": {
        "id": "LRjSkw2HQ8uT"
      },
      "id": "LRjSkw2HQ8uT"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Define Dataset Paths\n",
        "dataset_path = \"/content/drive/My Drive/EuroSAT_MS\"\n",
        "final_dataset_path = \"/content/drive/My Drive/EuroSAT_Final_Dataset\"\n",
        "\n",
        "# ‚úÖ Create the Final Dataset Folder\n",
        "os.makedirs(final_dataset_path, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Set Image Properties\n",
        "IMAGE_SIZE = (64, 64)   # Resize images to 64x64 pixels\n",
        "\n",
        "# ‚úÖ Select Specific Bands (B2, B3, B4, B8)\n",
        "BANDS = [1, 2, 3, 7]  # Sentinel-2 index starts from 0 (so B2=1, B3=2, B4=3, B8=7)\n",
        "\n",
        "TARGET_COUNT = 4000  # Ensure each category has 4,000 images\n"
      ],
      "metadata": {
        "id": "YAf0vo5dQ9PN"
      },
      "id": "YAf0vo5dQ9PN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a sample image to check available bands"
      ],
      "metadata": {
        "id": "zSCkKervRKja"
      },
      "id": "zSCkKervRKja"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573d69b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "573d69b5",
        "outputId": "c17eb8e9-e460-4269-acba-78ac04aa911a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Sample Image: /content/drive/My Drive/DEPIproject/EuroSAT/AnnualCrop/AnnualCrop_2002.tif\n",
            "üì° Number of Spectral Bands: 13\n",
            "üìä Band Names: (None, None, None, None, None, None, None, None, None, None, None, None, None)\n"
          ]
        }
      ],
      "source": [
        "sample_image_path = None\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".tif\"):\n",
        "            sample_image_path = os.path.join(root, file)\n",
        "            break\n",
        "    if sample_image_path:\n",
        "        break\n",
        "\n",
        "if sample_image_path:\n",
        "    with rasterio.open(sample_image_path) as src:\n",
        "        num_bands = src.count\n",
        "        print(f\"‚úÖ Sample Image: {sample_image_path}\")\n",
        "        print(f\"üì° Number of Spectral Bands: {num_bands}\")\n",
        "        print(f\"üìä Band Names: {src.descriptions}\")\n",
        "else:\n",
        "    print(\"‚ùå No images found in the dataset!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 3: Define Image Processing & Augmentation"
      ],
      "metadata": {
        "id": "ZCzni52pRaSS"
      },
      "id": "ZCzni52pRaSS"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Define Image Processing Function\n",
        "def process_tiff_image(image_path):\n",
        "    \"\"\"\n",
        "    Loads a TIFF image using rasterio, extracts all bands,\n",
        "    resizes the image, and normalizes pixel values to [0, 1].\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read(BANDS)  # Load all 13 bands\n",
        "            image = np.transpose(image, (1, 2, 0))  # Rearrange to (H, W, C)\n",
        "            image = cv2.resize(image, IMAGE_SIZE)  # Resize\n",
        "            image = image / 65535.0  # Normalize (Sentinel-2 max value is 65535)\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ‚úÖ Define Augmentation Pipeline\n",
        "augmentation = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.GaussianBlur(p=0.3),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Kkp7IJ49Ra7K"
      },
      "id": "Kkp7IJ49Ra7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 4: Load, Process & Augment Images"
      ],
      "metadata": {
        "id": "APDVpPetRtfL"
      },
      "id": "APDVpPetRtfL"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Load, Process, and Augment Images\n",
        "X, y = [], []\n",
        "category_counts = {}\n",
        "\n",
        "print(\"üîÑ Processing TIFF Images from EuroSAT...\")\n",
        "for category in tqdm(sorted(os.listdir(dataset_path))):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "\n",
        "    if os.path.isdir(category_path):\n",
        "        images = []\n",
        "        for file in os.listdir(category_path):\n",
        "            if file.lower().endswith(\".tif\"):\n",
        "                image_path = os.path.join(category_path, file)\n",
        "                img = process_tiff_image(image_path)\n",
        "                if img is not None:\n",
        "                    images.append(img)\n",
        "                    X.append(img)\n",
        "                    y.append(category)\n",
        "\n",
        "        # ‚úÖ Apply Augmentation Until Each Category Has 4,000 Images\n",
        "        current_count = len(images)\n",
        "        category_counts[category] = current_count\n",
        "        print(f\"üìä Found {current_count} images in {category}.\")\n",
        "\n",
        "        if current_count < TARGET_COUNT:\n",
        "            i = 0  # Augmentation index\n",
        "            while current_count < TARGET_COUNT:\n",
        "                image = images[i % len(images)]  # Cycle through images\n",
        "                augmented = augmentation(image=image)  # Apply augmentation\n",
        "                X.append(augmented[\"image\"])\n",
        "                y.append(category)\n",
        "\n",
        "                current_count += 1\n",
        "                i += 1\n",
        "\n",
        "            print(f\"‚úÖ Augmented {category} to {TARGET_COUNT} images!\")\n",
        "\n",
        "# ‚úÖ Convert to NumPy Arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"\\n‚úÖ Total Processed Images: {X.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "Uc0RZzJ3Rt-p"
      },
      "id": "Uc0RZzJ3Rt-p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 5: Compute NDVI for Each Image"
      ],
      "metadata": {
        "id": "qdlud74uRxnc"
      },
      "id": "qdlud74uRxnc"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Define NDVI Computation Function\n",
        "def compute_ndvi(image, nir_band=7, red_band=3):\n",
        "    \"\"\"\n",
        "    Computes NDVI using Near-Infrared (NIR) and Red bands.\n",
        "    \"\"\"\n",
        "    nir = image[:, :, nir_band].astype(float)\n",
        "    red = image[:, :, red_band].astype(float)\n",
        "    ndvi = (nir - red) / (nir + red + 1e-5)  # Avoid division by zero\n",
        "    return ndvi\n",
        "\n",
        "# ‚úÖ Compute NDVI for the Entire Dataset\n",
        "ndvi_maps = np.array([compute_ndvi(img) for img in X])\n",
        "\n",
        "print(\"\\n‚úÖ NDVI Computation Completed!\")\n",
        "print(f\"üìÇ NDVI shape: {ndvi_maps.shape}\")\n"
      ],
      "metadata": {
        "id": "CZLRM4AzRy2_"
      },
      "id": "CZLRM4AzRy2_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Section 6: Encode Labels & Save Final Dataset"
      ],
      "metadata": {
        "id": "gk3v16fAR0vt"
      },
      "id": "gk3v16fAR0vt"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Encode Labels (Convert Category Names to Integers)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print(\"\\nüìú Label Mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "# ‚úÖ Save the Final Dataset\n",
        "np.save(os.path.join(final_dataset_path, \"X.npy\"), X)\n",
        "np.save(os.path.join(final_dataset_path, \"y.npy\"), y_encoded)\n",
        "np.save(os.path.join(final_dataset_path, \"NDVI.npy\"), ndvi_maps)\n",
        "\n",
        "print(\"\\n‚úÖ Final Dataset Saved Successfully!\")\n",
        "print(f\"üìÇ X.npy (images), y.npy (labels), and NDVI.npy are stored in: {final_dataset_path}\")\n",
        "print(f\"Final Dataset Shape: X={X.shape}, y={y_encoded.shape}, NDVI={ndvi_maps.shape}\")\n"
      ],
      "metadata": {
        "id": "o5MtrrgcR1yx"
      },
      "id": "o5MtrrgcR1yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b0394614",
      "metadata": {
        "id": "b0394614"
      },
      "source": [
        "# **üöÄ Conclusion**\n",
        "This notebook successfully:\n",
        "- ‚úÖ Validated dataset integrity\n",
        "- ‚úÖ Checked image quality & distributions\n",
        "- ‚úÖ Confirmed the presence of **multispectral bands**\n",
        "- ‚úÖ Displayed sample images from different categories\n",
        "- ‚úÖ Preprocessed images (resize, normalize, augment)\n",
        "- ‚úÖ Computed & visualized NDVI for vegetation analysis\n",
        "\n",
        "Next Steps:\n",
        "- **Train a deep learning model** for land classification"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}